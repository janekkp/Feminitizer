{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Model_develop.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1OD6_sARmC66rnDDIBm2f3M4Go6uzP9t3",
      "authorship_tag": "ABX9TyP4MoxyIxbm0LeGc/24CY4g"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8m52_jcqH-N",
        "colab_type": "text"
      },
      "source": [
        "# Imports, dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeU4LTjsqUdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#General data packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "#Deep learning\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Sep8p4sMXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f58b2cf2-cba1-452b-d862-d420c0c723e3"
      },
      "source": [
        "full_fems = pd.read_csv(\"path/to/data\")\n",
        "full_fems = shuffle(full_fems)  # Shuffle dataset before train/dev/test split\n",
        "full_fems # Example words in dataset"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>forma_zenska</th>\n",
              "      <th>forma_meska</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5186</th>\n",
              "      <td>kochanka</td>\n",
              "      <td>kochanek</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>egzorcystka</td>\n",
              "      <td>egzorcysta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607</th>\n",
              "      <td>apiterapeutka</td>\n",
              "      <td>apiterapeuta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3692</th>\n",
              "      <td>zawadczanka</td>\n",
              "      <td>zawadczanin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>641</th>\n",
              "      <td>azjatka</td>\n",
              "      <td>azjata</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2354</th>\n",
              "      <td>bialanka</td>\n",
              "      <td>bialanin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>modniarka</td>\n",
              "      <td>modniarz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4250</th>\n",
              "      <td>realizatorka</td>\n",
              "      <td>realizator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>bursztyniarka</td>\n",
              "      <td>bursztyniarz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3418</th>\n",
              "      <td>sławkowianka</td>\n",
              "      <td>sławkowianin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6082 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       forma_zenska   forma_meska\n",
              "5186       kochanka      kochanek\n",
              "782     egzorcystka    egzorcysta\n",
              "607   apiterapeutka  apiterapeuta\n",
              "3692    zawadczanka   zawadczanin\n",
              "641         azjatka        azjata\n",
              "...             ...           ...\n",
              "2354       bialanka      bialanin\n",
              "159       modniarka      modniarz\n",
              "4250   realizatorka    realizator\n",
              "21    bursztyniarka  bursztyniarz\n",
              "3418   sławkowianka  sławkowianin\n",
              "\n",
              "[6082 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8XtaxJ2qPkW",
        "colab_type": "text"
      },
      "source": [
        "# Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcn7In9AtQ0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to add additional charater on the beginning and end of each female form\n",
        "input_forms = [word for word in full_fems.forma_meska]\n",
        "target_forms = [ \"\\t\" + word + \"\\n\" for word in full_fems.forma_zenska]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACL3EjfDqLxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Each character is represented as one-hot vector\n",
        "tokenizer_input = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer_input.fit_on_texts(input_forms)\n",
        "\n",
        "data_input = tokenizer_input.texts_to_sequences(input_forms)\n",
        "data_input = keras.preprocessing.sequence.pad_sequences(data_input, padding=\"post\")\n",
        "\n",
        "tokenizer_output = keras.preprocessing.text.Tokenizer(char_level=True, lower=True)\n",
        "tokenizer_output.fit_on_texts(target_forms)\n",
        "\n",
        "data_output = tokenizer_input.texts_to_sequences(target_forms)\n",
        "data_output = keras.preprocessing.sequence.pad_sequences(data_output, padding=\"post\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBH4Tjdeaf9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3c00e305-0ac9-4c3c-a57a-818d9176a576"
      },
      "source": [
        "tokenizer_input.word_index.keys()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['a', 'i', 'n', 'o', 'r', 't', 'e', 'z', 's', 'k', 'c', 'y', 'l', 'w', 'p', 'm', 'd', 'u', 'b', 'g', 'j', 'h', 'ł', 'f', 'ń', 'ż', 'ó', 'ś', 'ę', 'ą', 'ź', 'ć'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVfnZd4LtOih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_seq_len = max([len(word) for word in input_forms])\n",
        "input_characters = tokenizer_input.word_index.keys()\n",
        "\n",
        "output_seq_len = max([len(word) for word in target_forms])\n",
        "output_characters = tokenizer_output.word_index.keys()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWTqnCtJthxU",
        "colab_type": "text"
      },
      "source": [
        "I have only ~ 6000 pairs so I put about 10% to testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2cqFrIdtWNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_test = input_forms[-600:]\n",
        "input_forms = input_forms[:-600]\n",
        "\n",
        "target_forms_test = target_forms[-600:]\n",
        "target_forms = target_forms[:-600]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96q9D5-FuHYc",
        "colab_type": "text"
      },
      "source": [
        "Scheme for representing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6yO_xpKuFNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_data = np.zeros((len(input_forms), input_seq_len, len(input_characters) + 1))\n",
        "encoder_input_data_test = np.zeros((len(input_test), input_seq_len, len(input_characters) + 1))\n",
        "\n",
        "decoder_input_data = np.zeros((len(target_forms), output_seq_len, len(output_characters) +1 ))\n",
        "decoder_target_data = np.zeros((len(target_forms), output_seq_len, len(output_characters) +1 ))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SrsN6YbuUBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (input_form, target_form) in enumerate(zip(input_forms, target_forms)):\n",
        "  for t, char in enumerate(input_form):\n",
        "    encoder_input_data[i, t, tokenizer_input.word_index[char]] = 1.\n",
        "  for t, char in enumerate(target_form):\n",
        "    decoder_input_data[i, t, tokenizer_output.word_index[char]] = 1.\n",
        "    if t > 0:\n",
        "      decoder_target_data[i, t - 1, tokenizer_output.word_index[char]] = 1."
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_2kw824uPI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, input_form in enumerate(input_test):\n",
        "  for t, char in enumerate(input_form):\n",
        "    encoder_input_data_test[i, t, tokenizer_input.word_index[char]] = 1."
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SAvJSufvPHs",
        "colab_type": "text"
      },
      "source": [
        "# Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJy4Jw7wvi78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WordAccuracy(keras.metrics.Metric):\n",
        "\n",
        "  '''\n",
        "  Purpose of metric is to checkout how many words are \n",
        "  well-predicted from begining to end. Categorical Accuracy just gives us\n",
        "  information about how many charaters are well-predicted, but when it comes\n",
        "  to zeros in padding the model do not even learns to predict them,\n",
        "  so default \"accuracy\" can be misleading.\n",
        "  '''\n",
        "\n",
        "  def __init__(self, name='word_accuracy', **kwargs):\n",
        "    super(WordAccuracy, self).__init__(name=name, **kwargs)\n",
        "    self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
        "    self.count = self.add_weight(\"total\", initializer=\"zeros\")\n",
        "\n",
        "  @tf.function\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "    acc = 0\n",
        "\n",
        "    # For each word in batch\n",
        "    for i in range(tf.shape(y_true)[0]):\n",
        "    # Check where max == 1 - how long word is and how long padding is.\n",
        "      positions = tf.keras.backend.max(y_true[i], axis=1) == 1   \n",
        "    # Take out all maxes from predicted values.\n",
        "      pred = tf.argmax(y_pred[i], axis=1)       \n",
        "    # Take out all maxes from true values.\n",
        "      true = tf.argmax(y_true[i], axis=1)      \n",
        "    # If all important positions are same model predicted succesfully whole word.\n",
        "      if tf.keras.backend.all(true[positions] == pred[positions]):\n",
        "         acc += 1\n",
        "\n",
        "    acc = tf.cast(acc, dtype=\"float32\")\n",
        "\n",
        "    self.total.assign_add(acc)\n",
        "    self.count.assign_add(tf.cast(tf.shape(y_true)[0], dtype=\"float32\"))\n",
        "\n",
        "  def result(self):\n",
        "    return self.total / self.count\n",
        "\n",
        "  def reset_states(self):\n",
        "    self.total.assign(0)\n",
        "    self.count.assign(0)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDwTXjKguO9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 100\n",
        "\n",
        "encoder_input_train, encoder_input_val, decoder_input_train, \\\n",
        "decoder_input_val, decoder_target_train, decoder_target_val = \\\n",
        "train_test_split(encoder_input_data, decoder_input_data, decoder_target_data, test_size = .12)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((encoder_input_train, decoder_input_train, decoder_target_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(encoder_input_train)).batch(batch_size)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((encoder_input_val, decoder_input_val, decoder_target_val))\n",
        "val_dataset = val_dataset.batch(batch_size)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXzaaxHsllId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "a1d9c0ad-aecd-4d73-fcdd-4ca7ecda11ae"
      },
      "source": [
        "dimensions = [1024, 256]\n",
        "\n",
        "#Encoder architecture\n",
        "encoder_inputs = keras.layers.Input(shape=(None, len(input_characters) + 1))\n",
        "masked_input = keras.layers.Masking()(encoder_inputs)\n",
        "\n",
        "encoder_lstm1 = keras.layers.LSTM(dimensions[0], return_state=True, return_sequences=True)\n",
        "encoder_outputs, h1, c1 = encoder_lstm1(masked_input)\n",
        "\n",
        "encoder_lstm2 = keras.layers.LSTM(dimensions[1], return_state=True)\n",
        "_, h2, c2 = encoder_lstm2(encoder_outputs)\n",
        "\n",
        "encoder_states = [h1, c1, h2, c2]\n",
        "\n",
        "#Decoder architecture\n",
        "decoder_inputs = keras.layers.Input(shape=(None, len(output_characters) +1))\n",
        "masked_inputs = keras.layers.Masking()(decoder_inputs)\n",
        "\n",
        "decoder_lstm1 = keras.layers.LSTM(dimensions[0], return_sequences=True, return_state=True)\n",
        "decoder_outputs, dh1, dc1 = decoder_lstm1(masked_inputs, initial_state = [h1, c1])\n",
        "\n",
        "decoder_lstm2 = keras.layers.LSTM(dimensions[1], return_sequences=True, return_state=True)\n",
        "decoder_outputs_2, dh2, dc2 = decoder_lstm2(decoder_outputs, initial_state = [h2, c2])\n",
        "\n",
        "deep_dense = keras.layers.Dense(dimensions[1], activation = \"tanh\")\n",
        "deep_out = deep_dense(decoder_outputs_2)\n",
        "\n",
        "out_dense = keras.layers.Dense(len(output_characters) + 1, activation='softmax')\n",
        "outputs = out_dense(deep_out)\n",
        "\n",
        "#Full model\n",
        "feminitizer = keras.models.Model(inputs=[encoder_inputs, decoder_inputs], \n",
        "              outputs=outputs)\n",
        "\n",
        "feminitizer.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 33)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 35)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "masking (Masking)               (None, None, 33)     0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "masking_1 (Masking)             (None, None, 35)     0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, None, 1024), 4333568     masking[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 1024), 4341760     masking_1[0][0]                  \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 1311744     lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 256),  1311744     lstm_2[0][0]                     \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 256)    65792       lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 35)     8995        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 11,373,603\n",
            "Trainable params: 11,373,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgWCYgTExOrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_on_batch(X1, X2, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    y_pred = feminitizer([X1, X2], training=True)\n",
        "    main_loss = tf.reduce_mean(loss_fn(y, y_pred))\n",
        "    loss = tf.add_n([main_loss] + feminitizer.losses)\n",
        "    train_loss.append(loss)\n",
        "\n",
        "  gradients = tape.gradient(loss, feminitizer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, feminitizer.trainable_variables))\n",
        "  mean_loss(loss)\n",
        "\n",
        "  # Update metrics\n",
        "  for i, metric in enumerate(metrics):\n",
        "    metric(y, y_pred)\n",
        "\n",
        "@tf.function\n",
        "def valid_on_batch(X1, X2, y):\n",
        "\n",
        "  y_val_pred = feminitizer([X1, X2], training=False)\n",
        "  main_loss_val = tf.reduce_mean(loss_fn(y, y_val_pred))\n",
        "  validation_loss.append(main_loss_val)\n",
        "  mean_loss_val(main_loss_val)\n",
        "\n",
        "  # Update metrics\n",
        "  for i, metric in enumerate(val_metrics):\n",
        "    metric(y, y_val_pred)\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCoYpi9Lvym9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Custom progress bar for monitoring metrics\n",
        "def print_status_bar_val(iteration, total, loss, metrics=None):\n",
        "  metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
        "  for m in [loss] + (metrics or [])])\n",
        "  end = \"\" if iteration < total else \"\\n\"\n",
        "  print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
        "  end=end)\n",
        "\n",
        "def print_status_bar(iteration, total, loss, metrics=None):\n",
        "  metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
        "  for m in [loss] + (metrics or [])])\n",
        "  end = \"\" if iteration < total else \"\\n\"\n",
        "  print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
        "  end=end)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH_XRVK1YZDn",
        "colab_type": "text"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVrD7jIivs3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Value to compare with\n",
        "best_word_acc = tf.Variable(.8)\n",
        "\n",
        "# After experimeting with diffrent loss functions and optimizers those \n",
        "loss_fn = keras.losses.categorical_crossentropy\n",
        "optimizer = tfa.optimizers.LazyAdam()\n",
        "\n",
        "mean_loss = keras.metrics.Mean()\n",
        "mean_loss_val = keras.metrics.Mean()\n",
        "\n",
        "metrics = [keras.metrics.CategoricalAccuracy(), WordAccuracy()]\n",
        "val_metrics = [keras.metrics.CategoricalAccuracy(), WordAccuracy()]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "    print(\"\\nTraining set\")\n",
        "  \n",
        "    # Training\n",
        "    for step, (encoder_batch, decoder_batch, y_batch) in enumerate(train_dataset):\n",
        "      train_on_batch(encoder_batch, decoder_batch, y_batch)\n",
        "\n",
        "      print_status_bar(step * batch_size, len(encoder_input_train), mean_loss, metrics)\n",
        "\n",
        "\n",
        "    print(\"\\nValidation set:\")\n",
        "\n",
        "    # Validation\n",
        "    for step_val, (encoder_batch_val, decoder_batch_val, target_batch_val) in enumerate(val_dataset):\n",
        "      valid_on_batch(encoder_batch_val, decoder_batch_val, target_batch_val)\n",
        "\n",
        "    # Save the best model (model with highest validation word accuracy)\n",
        "    if val_metrics[1].result() > best_word_acc:\n",
        "      feminitizer.save('femz.h5')\n",
        "      best_word_acc = val_metrics[1].result()\n",
        "\n",
        "    print_status_bar_val(len(encoder_input_val), len(encoder_input_val), mean_loss_val, val_metrics)\n",
        "\n",
        "    # Reset metrics\n",
        "    for metric in [mean_loss] + metrics:\n",
        "      metric.reset_states()\n",
        "    for metric in [mean_loss_val] + val_metrics:\n",
        "      metric.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUkAMZlfwb2e",
        "colab_type": "text"
      },
      "source": [
        "# Building model and functions for new predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuqWHM4d0yeb",
        "colab_type": "text"
      },
      "source": [
        "Let's use the best saved model to make new predictions aka feminatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0In1vgz05mE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "936be520-03a9-468d-e298-d2c678dd830d"
      },
      "source": [
        "feminitizer_pred = keras.models.load_model(\"/content/femz.h5\")\n",
        "\n",
        "# We need to take out encoder internal states\n",
        "_, h1, c1 = feminitizer_pred.layers[4].output\n",
        "_, h2, c2 = feminitizer_pred.layers[6].output"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-iXjOLUwgSj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "7b1d527b-92a4-4df7-e004-3b2fcae6e49c"
      },
      "source": [
        "#Encoder model for prediction\n",
        "encoder_predictor = keras.models.Model(feminitizer_pred.input[0], [h1,c1, h2, c2])\n",
        "\n",
        "#Decoder model for prediction\n",
        "decoder_state_input_h1 = keras.layers.Input(shape=(dimensions[0],))\n",
        "decoder_state_input_c1 = keras.layers.Input(shape=(dimensions[0],))\n",
        "decoder_state_input_h2 = keras.layers.Input(shape=(dimensions[1],))\n",
        "decoder_state_input_c2 = keras.layers.Input(shape=(dimensions[1],))\n",
        "decoder_states_inputs = [decoder_state_input_h1, decoder_state_input_c1, \n",
        "                         decoder_state_input_h2, decoder_state_input_c2]\n",
        "\n",
        "\n",
        "d_o, state_h1, state_c1 = feminitizer_pred.layers[5](feminitizer_pred.input[1], initial_state=decoder_states_inputs[:2])\n",
        "\n",
        "d_o, state_h2, state_c2 = feminitizer_pred.layers[7](d_o, initial_state=decoder_states_inputs[-2:])\n",
        "\n",
        "decoder_states = [state_h1, state_c1, state_h2, state_c2]\n",
        "\n",
        "deep_out = feminitizer_pred.layers[8](d_o)\n",
        "decoder_outputs = feminitizer_pred.layers[9](deep_out)\n",
        "\n",
        "# decoder_outputs = decoder_dense(output)\n",
        "decoder_predictor = keras.models.Model(\n",
        "    [feminitizer_pred.input[1]] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "decoder_predictor.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 35)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 1024), 4341760     input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 256),  1311744     lstm_2[1][0]                     \n",
            "                                                                 input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 256)    65792       lstm_3[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 35)     8995        dense[1][0]                      \n",
            "==================================================================================================\n",
            "Total params: 5,728,291\n",
            "Trainable params: 5,728,291\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpVsGNIgbmAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save both models for future uses\n",
        "encoder_predictor.save(\"encoder_predict.h5\")\n",
        "\n",
        "decoder_predictor.save(\"decoder_predict.h5\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHqLDq9UisZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_pred = keras.models.load_model('encoder_predict.h5')\n",
        "\n",
        "decoder_pred = keras.models.load_model('decoder_predict.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTVIxJanwkFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # encode the input sequence to get the internal state vectors.\n",
        "  states_value = encoder_pred.predict(input_seq)\n",
        "  \n",
        "  # generate empty target sequence of length 1 with only the start character\n",
        "  target_seq = np.zeros((1, 1, len(output_characters)+1))\n",
        "  target_seq[0, 0, tokenizer_output.word_index['\\t']] = 1.\n",
        "  encoded_word = np.array([])\n",
        "\n",
        "\n",
        "  # loop for producing feminative\n",
        "  stop_condition = False\n",
        "  predicted_feminative = ''\n",
        "  while not stop_condition:\n",
        "    output_tokens, h1, c1, h2, c2 = decoder_pred.predict(\n",
        "            [target_seq] + states_value)\n",
        "    \n",
        "    # add token to predicted word\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = tokenizer_output.index_word[sampled_token_index]\n",
        "    predicted_feminative += sampled_char\n",
        "    \n",
        "    # if word is too long or next predicted character is \"\\n\" stop predicting\n",
        "    if (sampled_char == '\\n' or len(predicted_feminative) > output_seq_len):\n",
        "      stop_condition = True\n",
        "      \n",
        "    # update target\n",
        "    target_seq = np.zeros((1, 1, len(output_characters) +1))\n",
        "    target_seq[0, 0, sampled_token_index] = 1\n",
        "    \n",
        "    # update states\n",
        "    states_value = [h1, c1, h2, c2]\n",
        "    \n",
        "\n",
        "  return predicted_feminative"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m37oC4U36Wf",
        "colab_type": "text"
      },
      "source": [
        "# Enjoing results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeaqiI4e38-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04b4d309-3f77-4aa6-fb46-cf058b770146"
      },
      "source": [
        "fails = 0\n",
        "\n",
        "for seq_index in range(600):\n",
        "    input_seq = encoder_input_data_test[seq_index: seq_index + 1]\n",
        "    decoded_sentecne = decode_sequence(input_seq)\n",
        "    if decoded_sentecne.strip() != target_forms_test[seq_index].strip():\n",
        "      fails += 1\n",
        "\n",
        "print(fails/600)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpsCVeqYGwUj",
        "colab_type": "text"
      },
      "source": [
        "Error rate on test set is very similiar to validation set error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK80YwgT4Bkg",
        "colab_type": "text"
      },
      "source": [
        "# Custom feminization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utbiYt8B-tZi",
        "colab_type": "text"
      },
      "source": [
        "Function to generate custom feminatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09qebAPZ4D-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feminatize(words):\n",
        "  out_string = \"\"\n",
        "  words = words.split()\n",
        "  user_array = np.zeros((len(words), input_seq_len, len(input_characters) + 1))\n",
        "  for i, input_form in enumerate(user_array):\n",
        "    for t, char in enumerate(words[i].lower()):\n",
        "      user_array[i, t, tokenizer_input.word_index[char]] = 1.\n",
        "\n",
        "  for seq_index in range(len(user_array)):\n",
        "    input_seq = user_array[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "    out_string += decoded_sentence.strip()\n",
        "    out_string += \", \"\n",
        "\n",
        "  out_string = out_string[:-2]\n",
        "  return out_string"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qimOb4y04FR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cdf50067-c29d-4bee-e038-f01d484b9bc4"
      },
      "source": [
        "feminatize(\"informatyk poseł wariat niedźwiedź\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'informatyczka, posłanka, wariatka, niedźwiedzica'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    }
  ]
}
